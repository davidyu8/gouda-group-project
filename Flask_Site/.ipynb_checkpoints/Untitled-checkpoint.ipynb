{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06dd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# modeling\n",
    "import pathlib # for setting up checkpoint directory\n",
    "import os # ditto\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66377289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(n):\n",
    "\t''' imports the first n recipes from the recipe database. '''\n",
    "\n",
    "\twith sqlite3.connect(\"recipes1M.db\") as conn:\n",
    "\t\tquery = \\\n",
    "\t\tf\"\"\"\n",
    "\t\tSELECT R.title, R.ingredients, R.instructions\n",
    "\t\tFROM recipes R\n",
    "\t\tLIMIT ?\n",
    "\t\t\"\"\"\n",
    "\t\n",
    "\tdf = pd.read_sql_query(query, conn, params = [n])\n",
    "  \n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 100000\n",
    "data_raw = import_data(DATA_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2efe23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORD_TITLE = 'üìó '\n",
    "STOP_WORD_INGREDIENTS = '\\nü•ï\\n\\n'\n",
    "STOP_WORD_INSTRUCTIONS = '\\nüìù\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52430e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense(title, ingr, instr):\n",
    "\t''' \n",
    "\tEach recipe is stored across three columns in the original data. This\n",
    "\tfunction condenses them into a single string, with marked boundaries.\n",
    "\tThe concatenation steps in the end of this function were adapted from the code\n",
    "\tsource discussed.\n",
    "\t'''\n",
    "\n",
    "\t# set up the ingredients\n",
    "\ttemp1 = ingr # get string\n",
    "\ttemp1 = temp1[1:-1] # remove outer quotations\n",
    "\ttemp1 = temp1.split(\"\\\", \") # split into a list according to \",  sequence of those three characters\n",
    "\ttemp1 = [item[1:] for item in temp1] # remove leading quotation\n",
    "\ttemp1[len(temp1) - 1] = temp1[len(temp1) - 1][:-1] # remove ending quotation on last piece\n",
    "\n",
    "\t# set up the instructions\n",
    "\ttemp2 = instr\n",
    "\ttemp2 = temp2[1:-1]\n",
    "\ttemp2 = temp2.split(\"\\\", \")\n",
    "\ttemp2 = [item[1:] for item in temp2]\n",
    "\ttemp2[len(temp2) - 1] = temp2[len(temp2) - 1][:-1]\n",
    "    \n",
    "\tingr_string = ''\n",
    "\tfor ingredient in temp1:\n",
    "\t\tingr_string += f'‚Ä¢ {ingredient}\\n'\n",
    "\n",
    "\tinstr_string = ''\n",
    "\tfor instruction in temp2:\n",
    "\t\tinstr_string += f'‚Ä¢ {instruction}\\n'\n",
    "\n",
    "\treturn f'{STOP_WORD_TITLE}{title}\\n{STOP_WORD_INGREDIENTS}{ingr_string}{STOP_WORD_INSTRUCTIONS}{instr_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8269bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str = data_raw.apply(lambda x: condense(x.title, x.ingredients, x.instructions), axis = 1)\n",
    "\n",
    "# Oleksii Trekhleb\n",
    "MAX_RECIPE_LENGTH = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de4904ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(recipe):\n",
    "  ''' removes recipes that are too long. '''\n",
    "  return len(recipe) <= MAX_RECIPE_LENGTH \n",
    "\n",
    "data_filter = [recipe for recipe in data_str if filter(recipe)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781a66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_SIGN = '‚ê£' # will be appended to the end of each recipe\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters = '', # we do not want to filter our recipes\n",
    "    lower = False, # we want the model to recognize uppercase characters\n",
    "    split = '', # we are using characters, not words\n",
    "    char_level = True # we want a character-level RNN\n",
    ")\n",
    "\n",
    "# show the tokenizer all of the existing characters we have\n",
    "tokenizer.fit_on_texts([STOP_SIGN])\n",
    "tokenizer.fit_on_texts(data_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19c72d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe_GRU(n, seed, length, temperature):\n",
    "    \"\"\"\n",
    "    Function that generates recipes based on an RNN model.\n",
    "    RNN Model can easily be swapped, so further testing on optimizing a model can be done.\n",
    "    \n",
    "    n: Number of recipes to be generated.\n",
    "    seed: Ingredient name/seed to generate recipe with.\n",
    "    length: Length in characters of output recipe.\n",
    "    temperature: Temperature to be used when generating new recipe.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # load appropriate generator, more models can be added here later if developed\n",
    "    generator = tf.keras.models.load_model('generator_GRU')\n",
    "    generator.compile(optimizer = 'adam',\n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True))\n",
    "    # # initialize empty list of recipes\n",
    "    recipes = []\n",
    "\n",
    "    # # iterate n times to generate n recipes\n",
    "    for i in range(n):\n",
    "\n",
    "        start = STOP_WORD_TITLE + seed\n",
    "        indices = np.array(tokenizer.texts_to_sequences([start])) # vectorize\n",
    "        result = []\n",
    "\n",
    "        generator.reset_states() # make separate predictions independent\n",
    "\n",
    "        for char in range(length): # predict next character\n",
    "            preds = generator(indices)\n",
    "            preds = tf.squeeze(preds, 0) # reduce a dimension\n",
    "            preds = preds / temperature\n",
    "\n",
    "            # pick next character\n",
    "            pred_id = tf.random.categorical(preds, num_samples = 1)[-1, 0].numpy()\n",
    "        \n",
    "            # add the predicted character\n",
    "            indices = tf.expand_dims([pred_id], 0)\n",
    "            next_char = tokenizer.sequences_to_texts(indices.numpy())[0]\n",
    "            result.append(next_char)\n",
    "\n",
    "            recipes.append(start + ''.join(result))\n",
    "            # recipe = start + ''.join(result)\n",
    "\n",
    "            # print recipe\n",
    "            string = \"SEED: \" + str(seed) +  \", TEMPERATURE: \" + str(temperature) + '\\n'\n",
    "            string += str(recipes[len(recipes) - 1]).replace('\\n', '')\n",
    "\n",
    "            # final = \"----- RECIPE -----\" + '\\n'\n",
    "            # final += \"SEED: \" + str(seed) + \", TEMPERATURE: \" + str(temperature) + '\\n'\n",
    "            # final += recipe\n",
    "\n",
    "            return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5df6610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SEED: salmon, TEMPERATURE: 0.8\\nüìó salmon '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_recipe_GRU(1,'salmon', 500, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8ea53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B] *",
   "language": "python",
   "name": "conda-env-PIC16B-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
