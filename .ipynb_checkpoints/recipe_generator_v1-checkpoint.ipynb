{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# requires update to tensorflow 2.4\n",
    "# >>> conda activate PIC16B\n",
    "# >>> pip install tensorflow==2.4\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def retrieve(word):\n",
    "    '''\n",
    "    queries recipe database for titles including a specified word\n",
    "    Parameters:\n",
    "        word (str): keyword for parsing the recipe data\n",
    "    Returns:\n",
    "        pandas DataFrame with relevant recipes\n",
    "    '''\n",
    "    \n",
    "    with sqlite3.connect(\"recipes1M.db\") as conn:\n",
    "        cmd = \\\n",
    "        f\"\"\"\n",
    "        SELECT R.title\n",
    "        FROM recipes R\n",
    "        WHERE R.title LIKE \"%{word}%\"\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(cmd, conn)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = retrieve(\"salmon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(input):\n",
    "    lwer = tf.strings.lower(input)\n",
    "    punc = tf.strings.regex_replace(lwer, '[%s]' % re.escape(string.punctuation), '')\n",
    "    return punc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 5000\n",
    "sequence_length = 20\n",
    "\n",
    "vectorize = TextVectorization(\n",
    "    standardize = standardize,\n",
    "    max_tokens = max_tokens,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = sequence_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices(df) # convert to TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize.adapt(data) # set up the vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "for recipe in data.take(5):\n",
    "    print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_recipe(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize(text)\n",
    "\n",
    "data_vec = data.map(vectorize_recipe) # convert recipes to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_vec.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorize.get_vocabulary() # collect all the words used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_str(vec, vocab):\n",
    "    ''' converts numeric recipe to original title '''\n",
    "    arr = vec.numpy()\n",
    "    arr = arr[0]\n",
    "    title = \"\"\n",
    "    for num in arr:\n",
    "        title += vocab[num] + \" \"\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_vec:\n",
    "    out = num_to_str(item, vocabulary)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-strain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-scratch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-friday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B] *",
   "language": "python",
   "name": "conda-env-PIC16B-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
